# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/171VT0vprvoid028yiWeUt3qmgZ54RMan

https://levelup.gitconnected.com/graph-convolutional-network-node-classification-with-tensorflow-49d3e091ea15
https://github.com/tkipf/gcn/tree/master/gcn
"""

import numpy as np
import tensorflow as tf

from google.colab import drive

"""Load facebook data

"""

def load_data(path='/content/gdrive', file='/MyDrive/Colab Notebooks/Lab 3/facebook.npz'):
  drive.mount('/content/gdrive', force_remount=True);
  data = np.load("{}{}".format(path, file))
  return data

data = load_data()

def process_data(dataset):
  train_ds = tf.data.Dataset.zip((
    tf.data.Dataset.from_tensor_slices(data['features']
                                       [0:round(data['features'].size/3)]),
    tf.data.Dataset.from_tensor_slices(data['edges'][0:round(data['features'].size/3)])
  )).batch(64)

  valid_ds = tf.data.Dataset.zip((
    tf.data.Dataset.from_tensor_slices(data['features']
                                       [round(data['features'].size/3):
                                       round(2*data['features'].size/3)]),
    tf.data.Dataset.from_tensor_slices(data['edges'][round(data['features'].size/3):
                                       round(2*data['features'].size/3)])
  )).batch(64)

  test_ds = tf.data.Dataset.zip((
    tf.data.Dataset.from_tensor_slices(data['features']
                                       [round(2*data['features'].size/3):]),
    tf.data.Dataset.from_tensor_slices(data['edges']
                                       [round(2*data['features'].size/3):])
  )).batch(64)

  return train_ds, valid_ds, test_ds

for item in data.files:
    print(item)
    print(1)
    print(data[item])
    print(data[item].size)

train, valid, test = process_data(data)
print(train)