# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/171VT0vprvoid028yiWeUt3qmgZ54RMan
"""

import numpy as np
import torch
from google.colab import drive
import scipy.sparse as sp

train_size = 3 # Number to divide dataset by for train, valid and test datasets

def load_data(path='/content/gdrive', file='/MyDrive/Colab Notebooks/Lab 3/facebook.npz'):
  drive.mount('/content/gdrive', force_remount=True);
  data = np.load("{}{}".format(path, file))
  return data

def process_data(dataset):
  train_ds = range(0,round(dataset['features'].shape[0]/3))
  valid_ds = range(round(dataset['features'].shape[0]/3), 
                  round(2*dataset['features'].shape[0]/3))
  test_ds = range(round(2*dataset['features'].shape[0]/3), 
                  round(dataset['features'].shape[0]))

  train_ds = torch.LongTensor(train_ds)
  valid_ds = torch.LongTensor(valid_ds)
  test_ds = torch.LongTensor(test_ds)

  features = torch.as_tensor(dataset['features'])
  target = torch.from_numpy(dataset['target'])
  edges = torch.from_numpy(dataset['edges'])

  return train_ds, valid_ds, test_ds, features, target, edges

def normalize(mx):
  r_inv = np.power(np.array(mx.sum(1)), -1).flatten()
  r_inv[np.isinf(r_inv)] = 0.
  r_mat_inv = sp.diags(r_inv)
  mx = r_mat_inv.dot(mx)
  return mx

def sparse_mx_to_sparse_tensor(mx):
  mx = mx.tocoo().astype(np.float32)
  indices = torch.from_numpy(
      np.vstack((mx.row, mx.col)).astype(np.int64))
  values = torch.from_numpy(mx.data)
  shape = torch.Size(mx.shape)
  return torch.sparse.FloatTensor(indices, values, shape)

def adj_matrix(dataset):
  edge_size = round(dataset['edges'].shape[0]/train_size)
  target_size = round(dataset['target'].shape[0]/train_size)

  adj = sp.coo_matrix((np.ones(dataset['edges'].shape[0]), 
                       (dataset['edges'][0:dataset['edges'].shape[0], 0], 
                        dataset['edges'][0:dataset['edges'].shape[0], 1])),
                      shape=(dataset['target'].shape[0], dataset['target'].shape[0]), 
                      dtype=np.float32)
  adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)
  adj = normalize(adj + sp.eye(adj.shape[0]))
  adj = sparse_mx_to_sparse_tensor(adj)
  return adj